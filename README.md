# DSCI-412-Creating-a-GitHub-Account
What I learn in each week of my Predictive Modeling Class
 Week 1
- Unsupervised we observe a vector of measurements but not associated to the response. The situation is referred to as unsupervised because we lack a response variable that can supervise our analysis
- A model’s prediction error on the data that it trained from is called training error. A model’s prediction error on new data is called generalization error. 

Week 2
- Data exploration uses a combination of summary statistics - means and medians, variances, and counts - and visualization, or graphs of the data. You can spot some problems just by using summary statistics; other problems are easier to find visually.
- Monetary amounts—incomes, customer value, account, or purchase sizes—are some of the most commonly encountered sources of skewed distributions in data science applications. Taking the log of the data can restore symmetry to it.

Week 3
- With linear regression, you think in terms of residuals. You look for variables that correlate with your errors and add them to try and eliminate systematic modeling errors.
- Linear regression can predict well even in the presence of correlated variables, but correlated variables lower the quality of the advice.

Week 4
- The Logistic regression predicts the probability y that an instance belongs to a specific category 
- Each row in a confusion matrix represents an actual class, while each column represents a predicted class. It reports the number of false positives, false negatives, true positives, and true negatives. 

Week 5
- Assume the response, Y, are independent but they don’t have to normally distributed. It assume a distribution from an exponential family.

- There are three advantages to GLMs: robustness, adaptability, and interpretability. Because they can be used with a variety of data types, probability distributions, and link functions, these models are adaptable

Week 6
- Tree models are simple and easy to understand. It is easy to explain it to the management. To build a tree model for a regression problem, we need to minimize the mean square errors (MSE)

- Build a decision tree model on each training set using some random predictors, typically only a small portion of the predictors are used to construct the decision trees.

Week 7
- The regression and classification models have both response and features/predictors. After we build the predictive models, we may check our model by comparing the true response to the predicted response

- Unsupervised learning has only features. Since we don’t have the true observation, instead of forecasting, we are interested in discovering unknown subgroups/clusters. 

Week 8
- The first audience you’ll have to prepare documentation for is yourself and your peers. You may need to return to previous work months later, and it may be in an urgent situation like an important bug fix, presentation, or feature improvement.

- Git is a version control system, a tool that tracks changes to your code and shares those changes with others. Git allows for multiple people to work on the same file at the same time. 


